{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af739183",
   "metadata": {},
   "source": [
    "MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e09abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.stats import poisson\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë”© ë° í†µí•©\n",
    "input_dir = '../data/datas/input'\n",
    "csv_files = sorted([f for f in os.listdir(input_dir) if f.startswith(\"input_\") and f.endswith(\".csv\")])\n",
    "\n",
    "season_dfs = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(os.path.join(input_dir, file))\n",
    "    df['season'] = file.replace('final_', '').replace('.csv', '')\n",
    "    season_dfs.append(df)\n",
    "\n",
    "df = pd.concat(season_dfs, ignore_index=True)\n",
    "df = df.sort_values('date')\n",
    "\n",
    "# 2. í”¼ì²˜ êµ¬ì„± ë° ì¸ì½”ë”©\n",
    "target_cols = ['home_team_goal_count', 'away_team_goal_count']\n",
    "meta_cols_to_drop = ['date_GMT', 'date', 'season', 'home_result', 'away_result']\n",
    "X_raw = df.drop(columns=target_cols + meta_cols_to_drop, errors='ignore')\n",
    "X_raw = X_raw.select_dtypes(include=['number'])\n",
    "\n",
    "team_dummies = pd.get_dummies(df[['home_team', 'away_team']], prefix=['home', 'away'])\n",
    "X = pd.concat([X_raw, team_dummies], axis=1).dropna()\n",
    "\n",
    "y_home = df.loc[X.index, 'home_team_goal_count']\n",
    "y_away = df.loc[X.index, 'away_team_goal_count']\n",
    "\n",
    "# 3. í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
    "n = len(X)\n",
    "train_end = int(n * 0.6)\n",
    "val_end = int(n * 0.8)\n",
    "\n",
    "X_train, X_val, X_test = X.iloc[:train_end], X.iloc[train_end:val_end], X.iloc[val_end:]\n",
    "y_home_train, y_home_val, y_home_test = y_home.iloc[:train_end], y_home.iloc[train_end:val_end], y_home.iloc[val_end:]\n",
    "y_away_train, y_away_val, y_away_test = y_away.iloc[:train_end], y_away.iloc[train_end:val_end], y_away.iloc[val_end:]\n",
    "\n",
    "# 4. ëª¨ë¸ í•™ìŠµ + early stopping\n",
    "eval_set_home = [(X_train, y_home_train), (X_val, y_home_val)]\n",
    "eval_set_away = [(X_train, y_away_train), (X_val, y_away_val)]\n",
    "\n",
    "#4-1.\n",
    "\"\"\" model_home = XGBRegressor(objective=\"reg:squarederror\", n_estimators=1000, max_depth=4, eval_metric=\"rmse\", verbosity=1)\n",
    "model_away = XGBRegressor(objective=\"reg:squarederror\", n_estimators=1000, max_depth=4, eval_metric=\"rmse\", verbosity=1) \"\"\"\n",
    "\n",
    "#4-2.\n",
    "\"\"\" model_home = XGBRegressor(objective=\"reg:squarederror\", n_estimators=1000, max_depth=4, eval_metric=\"rmse\", verbosity=1)\n",
    "model_away = XGBRegressor(objective=\"reg:squarederror\", n_estimators=1000, max_depth=4, eval_metric=\"rmse\", verbosity=1) \"\"\"\n",
    "\n",
    "#4-3.\n",
    "common_params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"n_estimators\": 1000,\n",
    "    \"max_depth\": 5,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"min_child_weight\": 5,\n",
    "    \"gamma\": 1,\n",
    "    \"reg_alpha\": 1,\n",
    "    \"reg_lambda\": 1,\n",
    "    \"verbosity\": 1\n",
    "}\n",
    "model_home = XGBRegressor(**common_params)\n",
    "model_away = XGBRegressor(**common_params)\n",
    "\n",
    "print(\"ğŸ  Home Goal Model Training:\")\n",
    "model_home.fit(X_train, y_home_train, eval_set=eval_set_home, verbose=True)\n",
    "\n",
    "print(\"\\nğŸšŒ Away Goal Model Training:\")\n",
    "model_away.fit(X_train, y_away_train, eval_set=eval_set_away, verbose=True)\n",
    "\n",
    "evals_result_home = model_home.evals_result()\n",
    "evals_result_away = model_away.evals_result()\n",
    "\n",
    "# 4-1. í•™ìŠµ ê³¡ì„  ì‹œê°í™”\n",
    "def plot_learning_curve(evals_result, label=\"home\"):\n",
    "    train_metric = evals_result['validation_0']['rmse']\n",
    "    val_metric = evals_result['validation_1']['rmse']\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_metric, label='Train RMSE')\n",
    "    plt.plot(val_metric, label='Validation RMSE')\n",
    "    plt.title(f\"{label.capitalize()} Model - RMSE over Epochs\")\n",
    "    plt.xlabel(\"Boosting Round\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curve(evals_result_home, label=\"home\")\n",
    "plot_learning_curve(evals_result_away, label=\"away\")\n",
    "\n",
    "# 5. í‰ê°€ í•¨ìˆ˜\n",
    "def evaluate(model, X, y_true, name=\"home\"):\n",
    "    y_pred = model.predict(X).round().astype(int)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"[{name.upper()}] - RMSE: {rmse:.3f}, MAE: {mae:.3f}, RÂ²: {r2:.3f}\")\n",
    "    return y_pred, rmse, mae, r2\n",
    "\n",
    "# 6. Poisson ê¸°ë°˜ Top-3 ì ìˆ˜ ì˜ˆì¸¡\n",
    "def predict_scores_with_prob(x, max_goal=5, top_k=3):\n",
    "    mu_home = model_home.predict(x)[0]\n",
    "    mu_away = model_away.predict(x)[0]\n",
    "    result = []\n",
    "    rest_prob = 0\n",
    "\n",
    "    for h in range(max_goal + 1):\n",
    "        for a in range(max_goal + 1):\n",
    "            p = poisson.pmf(h, mu_home) * poisson.pmf(a, mu_away)\n",
    "            result.append(((h, a), p))\n",
    "\n",
    "    for h in range(max_goal + 1):\n",
    "        rest_prob += poisson.pmf(h, mu_home) * (1 - poisson.cdf(max_goal, mu_away))\n",
    "        rest_prob += (1 - poisson.cdf(max_goal, mu_home)) * poisson.pmf(h, mu_away)\n",
    "    rest_prob -= (1 - poisson.cdf(max_goal, mu_home)) * (1 - poisson.cdf(max_goal, mu_away))\n",
    "\n",
    "    result.append(((\"5+\", \"5+\"), rest_prob))\n",
    "    return {\n",
    "        \"home_expected_goals\": mu_home,\n",
    "        \"away_expected_goals\": mu_away,\n",
    "        \"top_predictions\": sorted(result, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    }\n",
    "\n",
    "# 7. ê²€ì¦/í…ŒìŠ¤íŠ¸ í‰ê°€\n",
    "print(\"âœ… ê²€ì¦ ì„±ëŠ¥:\")\n",
    "y_home_val_pred, _, _, _ = evaluate(model_home, X_val, y_home_val, \"home_val\")\n",
    "y_away_val_pred, _, _, _ = evaluate(model_away, X_val, y_away_val, \"away_val\")\n",
    "\n",
    "print(\"\\nâœ… í…ŒìŠ¤íŠ¸ ì„±ëŠ¥:\")\n",
    "y_home_test_pred, _, _, _ = evaluate(model_home, X_test, y_home_test, \"home_test\")\n",
    "y_away_test_pred, _, _, _ = evaluate(model_away, X_test, y_away_test, \"away_test\")\n",
    "\n",
    "# 8. Top-3 ì •ë‹µ í¬í•¨ ì—¬ë¶€ ê³„ì‚°\n",
    "results = []\n",
    "for i in tqdm(range(len(X_test))):\n",
    "    x = X_test.iloc[[i]]\n",
    "    true_home = y_home_test.iloc[i]\n",
    "    true_away = y_away_test.iloc[i]\n",
    "    pred = predict_scores_with_prob(x, top_k=3)\n",
    "    top_scores = [f\"{h}-{a}\" for (h, a), _ in pred[\"top_predictions\"]]\n",
    "    true_score = f\"{true_home}-{true_away}\"\n",
    "    hit = true_score in top_scores\n",
    "\n",
    "    results.append({\n",
    "        \"True Score\": true_score,\n",
    "        \"Top-1\": top_scores[0],\n",
    "        \"Top-2\": top_scores[1] if len(top_scores) > 1 else \"-\",\n",
    "        \"Top-3\": top_scores[2] if len(top_scores) > 2 else \"-\",\n",
    "        \"Hit in Top-3\": hit\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nğŸ“Š í…ŒìŠ¤íŠ¸ ì „ì²´ì—ì„œ ì‹¤ì œ ìŠ¤ì½”ì–´ê°€ Top-3 ì•ˆì— í¬í•¨ëœ ë¹„ìœ¨:\")\n",
    "print(f\"â†’ {df_results['Hit in Top-3'].mean():.2%}\")\n",
    "\n",
    "# 9. ì‹œê°í™”\n",
    "sns.countplot(data=df_results, x=\"Hit in Top-3\")\n",
    "plt.title(\"Are actual scores included in the Top-3 predictions?\")\n",
    "plt.xlabel(\"Included in Top 3\")\n",
    "plt.ylabel(\"Number of cases\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Top-3 ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ:\")\n",
    "print(df_results.head(10))\n",
    "\n",
    "# 10. Feature ì¤‘ìš”ë„ ì‹œê°í™”\n",
    "def plot_feature_importance(model, X_val, y_val, title=\"Permutation Importance\", top_n=20):\n",
    "    result = permutation_importance(model, X_val, y_val, n_repeats=10, random_state=42, scoring='neg_mean_squared_error')\n",
    "    importance_series = pd.Series(result.importances_mean, index=X_val.columns)\n",
    "    top_features = importance_series.sort_values(ascending=False).head(top_n)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_features.sort_values().plot(kind='barh')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Mean Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š Feature Importance (Home Goal Model)\")\n",
    "plot_feature_importance(model_home, X_val, y_home_val, title=\"Home Goal Feature Importance\", top_n=20)\n",
    "\n",
    "print(\"\\nğŸ“Š Feature Importance (Away Goal Model)\")\n",
    "plot_feature_importance(model_away, X_val, y_away_val, title=\"Away Goal Feature Importance\", top_n=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bed18e2",
   "metadata": {},
   "source": [
    "MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5910174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.stats import poisson\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "#ë°ì´í„° ë¡œë”© ë° í†µí•©\n",
    "input_dir = '../../data/datas/2/final'\n",
    "csv_files = sorted([f for f in os.listdir(input_dir) if f.startswith(\"final_\") and f.endswith(\".csv\")])\n",
    "\n",
    "season_dfs = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(os.path.join(input_dir, file))\n",
    "    df['season'] = file.replace('final_', '').replace('.csv', '')\n",
    "    season_dfs.append(df)\n",
    "\n",
    "df = pd.concat(season_dfs, ignore_index=True)\n",
    "df['date'] = pd.to_datetime(df['date_GMT'], errors='coerce')\n",
    "df = df.sort_values('date')\n",
    "\n",
    "#í”¼ì²˜ êµ¬ì„± ë° ì¸ì½”ë”©\n",
    "target_cols = ['home_team_goal_count', 'away_team_goal_count']\n",
    "meta_cols_to_drop = ['date_GMT', 'date', 'season', 'home_result', 'away_result', 'home_gk_save_pct', 'away_gk_save_pct']\n",
    "X_raw = df.drop(columns=target_cols + meta_cols_to_drop, errors='ignore')\n",
    "X_raw = X_raw.select_dtypes(include=['number'])  # ìˆ«ìí˜•ë§Œ ì‚¬ìš©\n",
    "\n",
    "team_dummies = pd.get_dummies(df[['home_team_name', 'away_team_name']], prefix=['home', 'away'])\n",
    "X = pd.concat([X_raw, team_dummies], axis=1).dropna()\n",
    "\n",
    "y_home = df.loc[X.index, 'home_team_goal_count']\n",
    "y_away = df.loc[X.index, 'away_team_goal_count']\n",
    "\n",
    "#í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
    "n = len(X)\n",
    "train_end = int(n * 0.6)\n",
    "val_end = int(n * 0.8)\n",
    "\n",
    "X_train, X_val, X_test = X.iloc[:train_end], X.iloc[train_end:val_end], X.iloc[val_end:]\n",
    "y_home_train, y_home_val, y_home_test = y_home.iloc[:train_end], y_home.iloc[train_end:val_end], y_home.iloc[val_end:]\n",
    "y_away_train, y_away_val, y_away_test = y_away.iloc[:train_end], y_away.iloc[train_end:val_end], y_away.iloc[val_end:]\n",
    "\n",
    "eval_set_home = [(X_train, y_home_train), (X_val, y_home_val)]\n",
    "eval_set_away = [(X_train, y_away_train), (X_val, y_away_val)]\n",
    "\n",
    "#ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "common_params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"n_estimators\": 1000,\n",
    "    \"max_depth\": 5,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"min_child_weight\": 5,\n",
    "    \"gamma\": 1,\n",
    "    \"reg_alpha\": 1,\n",
    "    \"reg_lambda\": 1,\n",
    "    \"verbosity\": 1\n",
    "}\n",
    "\n",
    "\n",
    "model_home = XGBRegressor(**common_params)\n",
    "model_away = XGBRegressor(**common_params)\n",
    "\n",
    "print(\"ğŸ  Home Goal Model Training:\")\n",
    "model_home.fit(X_train, y_home_train, eval_set=eval_set_home, verbose=True)\n",
    "print(\"\\nğŸšŒ Away Goal Model Training:\")\n",
    "model_away.fit(X_train, y_away_train, eval_set=eval_set_away, verbose=True)\n",
    "\n",
    "evals_result_home = model_home.evals_result()\n",
    "evals_result_away = model_away.evals_result()\n",
    "\n",
    "def plot_learning_curve(evals_result, label=\"home\"):\n",
    "    train_metric = evals_result['validation_0']['rmse']\n",
    "    val_metric = evals_result['validation_1']['rmse']\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_metric, label='Train RMSE')\n",
    "    plt.plot(val_metric, label='Validation RMSE')\n",
    "    plt.title(f\"{label.capitalize()} Model - RMSE over Epochs\")\n",
    "    plt.xlabel(\"Boosting Round\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curve(evals_result_home, label=\"home\")\n",
    "plot_learning_curve(evals_result_away, label=\"away\")\n",
    "\n",
    "#í‰ê°€ í•¨ìˆ˜\n",
    "def evaluate(model, X, y_true, name=\"home\"):\n",
    "    y_pred = model.predict(X).round().astype(int)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"[{name.upper()}] - RMSE: {rmse:.3f}, MAE: {mae:.3f}, RÂ²: {r2:.3f}\")\n",
    "    return y_pred, rmse, mae, r2\n",
    "\n",
    "#Poisson ê¸°ë°˜ Top-3 ì ìˆ˜ ì˜ˆì¸¡\n",
    "def predict_scores_with_prob(x, max_goal=5, top_k=3):\n",
    "    mu_home = model_home.predict(x)[0]\n",
    "    mu_away = model_away.predict(x)[0]\n",
    "    result = []\n",
    "    \n",
    "    home_win_prob = 0\n",
    "    draw_prob = 0\n",
    "    away_win_prob = 0\n",
    "    rest_prob = 0\n",
    "\n",
    "    for h in range(max_goal + 1):\n",
    "        for a in range(max_goal + 1):\n",
    "            p = poisson.pmf(h, mu_home) * poisson.pmf(a, mu_away)\n",
    "            result.append(((h, a), p))\n",
    "            if h > a:\n",
    "                home_win_prob += p\n",
    "            elif h == a:\n",
    "                draw_prob += p\n",
    "            else:\n",
    "                away_win_prob += p\n",
    "\n",
    "    # \"5+ goals\" ì˜ˆì™¸ ì²˜ë¦¬ í™•ë¥  ê³„ì‚°\n",
    "    for h in range(max_goal + 1):\n",
    "        rest_prob += poisson.pmf(h, mu_home) * (1 - poisson.cdf(max_goal, mu_away))\n",
    "        rest_prob += (1 - poisson.cdf(max_goal, mu_home)) * poisson.pmf(h, mu_away)\n",
    "    rest_prob -= (1 - poisson.cdf(max_goal, mu_home)) * (1 - poisson.cdf(max_goal, mu_away))\n",
    "\n",
    "    result.append(((\"5+\", \"5+\"), rest_prob))\n",
    "\n",
    "    # ì •ê·œí™”ëœ ìŠ¹/ë¬´/íŒ¨ í™•ë¥ \n",
    "    total = home_win_prob + draw_prob + away_win_prob\n",
    "    home_win_prob /= total\n",
    "    draw_prob /= total\n",
    "    away_win_prob /= total\n",
    "\n",
    "    return {\n",
    "        \"home_expected_goals\": mu_home,\n",
    "        \"away_expected_goals\": mu_away,\n",
    "        \"top_predictions\": sorted(result, key=lambda x: x[1], reverse=True)[:top_k],\n",
    "        \"home_win_prob\": home_win_prob,\n",
    "        \"draw_prob\": draw_prob,\n",
    "        \"away_win_prob\": away_win_prob\n",
    "    }\n",
    "\n",
    "# í‰ê°€ ê²°ê³¼ ì¶œë ¥\n",
    "print(\"âœ… ê²€ì¦ ì„±ëŠ¥:\")\n",
    "y_home_val_pred, _, _, _ = evaluate(model_home, X_val, y_home_val, \"home_val\")\n",
    "y_away_val_pred, _, _, _ = evaluate(model_away, X_val, y_away_val, \"away_val\")\n",
    "\n",
    "print(\"\\nâœ… í…ŒìŠ¤íŠ¸ ì„±ëŠ¥:\")\n",
    "y_home_test_pred, _, _, _ = evaluate(model_home, X_test, y_home_test, \"home_test\")\n",
    "y_away_test_pred, _, _, _ = evaluate(model_away, X_test, y_away_test, \"away_test\")\n",
    "    \n",
    "# Poisson Top-3 ê²°ê³¼ í™•ì¸\n",
    "results = []\n",
    "for i in tqdm(range(len(X_test))):\n",
    "    x = X_test.iloc[[i]]\n",
    "    true_home = y_home_test.iloc[i]\n",
    "    true_away = y_away_test.iloc[i]\n",
    "    pred = predict_scores_with_prob(x, top_k=3)\n",
    "    top_scores = [f\"{h}-{a}\" for (h, a), _ in pred[\"top_predictions\"]]\n",
    "    true_score = f\"{true_home}-{true_away}\"\n",
    "    hit = true_score in top_scores\n",
    "\n",
    "    results.append({\n",
    "        \"True Score\": true_score,\n",
    "        \"Top-1\": top_scores[0],\n",
    "        \"Top-2\": top_scores[1] if len(top_scores) > 1 else \"-\",\n",
    "        \"Top-3\": top_scores[2] if len(top_scores) > 2 else \"-\",\n",
    "        \"Hit in Top-3\": hit\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nğŸ“Š í…ŒìŠ¤íŠ¸ ì „ì²´ì—ì„œ ì‹¤ì œ ìŠ¤ì½”ì–´ê°€ Top-3 ì•ˆì— í¬í•¨ëœ ë¹„ìœ¨:\")\n",
    "print(f\"â†’ {df_results['Hit in Top-3'].mean():.2%}\")\n",
    "\n",
    "# ì‹œê°í™”\n",
    "sns.countplot(data=df_results, x=\"Hit in Top-3\")\n",
    "plt.title(\"Are actual scores included in the Top-3 predictions?\")\n",
    "plt.xlabel(\"Included in Top 3\")\n",
    "plt.ylabel(\"number of cases\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Top-3 ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ:\")\n",
    "print(df_results.head(10))\n",
    "\n",
    "# Feature ì¤‘ìš”ë„ ì‹œê°í™”\n",
    "def plot_feature_importance(model, X_val, y_val, title=\"Permutation Importance\", top_n=20):\n",
    "    result = permutation_importance(model, X_val, y_val, n_repeats=10, random_state=42, scoring='neg_mean_squared_error')\n",
    "    importance_series = pd.Series(result.importances_mean, index=X_val.columns)\n",
    "    top_features = importance_series.sort_values(ascending=False).head(top_n)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_features.sort_values().plot(kind='barh')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Mean Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“Š Feature Importance (Home Goal Model)\")\n",
    "plot_feature_importance(model_home, X_val, y_home_val, title=\"Home Goal Feature Importance\", top_n=20)\n",
    "\n",
    "print(\"\\nğŸ“Š Feature Importance (Away Goal Model)\")\n",
    "plot_feature_importance(model_away, X_val, y_away_val, title=\"Away Goal Feature Importance\", top_n=20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0f997",
   "metadata": {},
   "source": [
    "Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f32fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.stats import poisson\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "#ë°ì´í„° ë¡œë”© ë° í†µí•©\n",
    "input_dir = '../../data/datas/2/final'\n",
    "csv_files = sorted([f for f in os.listdir(input_dir) if f.startswith(\"final_\") and f.endswith(\".csv\")])\n",
    "\n",
    "season_dfs = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(os.path.join(input_dir, file))\n",
    "    df['season'] = file.replace('final_', '').replace('.csv', '')\n",
    "    season_dfs.append(df)\n",
    "\n",
    "df = pd.concat(season_dfs, ignore_index=True)\n",
    "df['date'] = pd.to_datetime(df['date_GMT'], errors='coerce')\n",
    "df = df.sort_values('date')\n",
    "\n",
    "#í”¼ì²˜ êµ¬ì„± ë° ì¸ì½”ë”©\n",
    "target_cols = ['home_team_goal_count', 'away_team_goal_count']\n",
    "meta_cols_to_drop = ['date_GMT', 'date', 'season', 'home_result', 'away_result', 'home_gk_save_pct', 'away_gk_save_pct']\n",
    "X_raw = df.drop(columns=target_cols + meta_cols_to_drop, errors='ignore')\n",
    "X_raw = X_raw.select_dtypes(include=['number'])  # ìˆ«ìí˜•ë§Œ ì‚¬ìš©\n",
    "\n",
    "team_dummies = pd.get_dummies(df[['home_team_name', 'away_team_name']], prefix=['home', 'away'])\n",
    "X = pd.concat([X_raw, team_dummies], axis=1).dropna()\n",
    "\n",
    "y_home = df.loc[X.index, 'home_team_goal_count']\n",
    "y_away = df.loc[X.index, 'away_team_goal_count']\n",
    "\n",
    "#í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
    "n = len(X)\n",
    "train_end = int(n * 0.6)\n",
    "val_end = int(n * 0.8)\n",
    "\n",
    "X_train, X_val, X_test = X.iloc[:train_end], X.iloc[train_end:val_end], X.iloc[val_end:]\n",
    "y_home_train, y_home_val, y_home_test = y_home.iloc[:train_end], y_home.iloc[train_end:val_end], y_home.iloc[val_end:]\n",
    "y_away_train, y_away_val, y_away_test = y_away.iloc[:train_end], y_away.iloc[train_end:val_end], y_away.iloc[val_end:]\n",
    "\n",
    "eval_set_home = [(X_train, y_home_train), (X_val, y_home_val)]\n",
    "eval_set_away = [(X_train, y_away_train), (X_val, y_away_val)]\n",
    "\n",
    "#ëª¨ë¸ í•™ìŠµ\n",
    "common_params1 = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"n_estimators\": 1000,\n",
    "    \"max_depth\": 5,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"subsample\": 0.9,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"min_child_weight\": 3,\n",
    "    \"gamma\": 1,\n",
    "    \"reg_alpha\": 1,\n",
    "    \"reg_lambda\": 1,\n",
    "    \"verbosity\": 1\n",
    "}\n",
    "\n",
    "model_home = XGBRegressor(**common_params1)\n",
    "model_away = XGBRegressor(**common_params1)\n",
    "\n",
    "print(\"ğŸ  Home Goal Model Training:\")\n",
    "model_home.fit(X_train, y_home_train, eval_set=eval_set_home, verbose=True)\n",
    "print(\"\\nğŸšŒ Away Goal Model Training:\")\n",
    "model_away.fit(X_train, y_away_train, eval_set=eval_set_away, verbose=True)\n",
    "\n",
    "evals_result_home = model_home.evals_result()\n",
    "evals_result_away = model_away.evals_result()\n",
    "\n",
    "def plot_learning_curve(evals_result, label=\"home\"):\n",
    "    train_metric = evals_result['validation_0']['rmse']\n",
    "    val_metric = evals_result['validation_1']['rmse']\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train_metric, label='Train RMSE')\n",
    "    plt.plot(val_metric, label='Validation RMSE')\n",
    "    plt.title(f\"{label.capitalize()} Model - RMSE over Epochs\")\n",
    "    plt.xlabel(\"Boosting Round\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curve(evals_result_home, label=\"home\")\n",
    "plot_learning_curve(evals_result_away, label=\"away\")\n",
    "\n",
    "#í‰ê°€ í•¨ìˆ˜\n",
    "def evaluate(model, X, y_true, name=\"home\"):\n",
    "    y_pred = model.predict(X).round().astype(int)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"[{name.upper()}] - RMSE: {rmse:.3f}, MAE: {mae:.3f}, RÂ²: {r2:.3f}\")\n",
    "    return y_pred, rmse, mae, r2\n",
    "\n",
    "def predict_scores_with_prob(x, max_goal=3, top_k=3):\n",
    "    mu_home = model_home.predict(x)[0]\n",
    "    mu_away = model_away.predict(x)[0]\n",
    "\n",
    "    # ê¸°ëŒ€ë“ì (mu) ì œí•œ\n",
    "    mu_home = min(mu_home, max_goal)\n",
    "    mu_away = min(mu_away, max_goal)\n",
    "\n",
    "    result = []\n",
    "    home_win_prob = 0\n",
    "    draw_prob = 0\n",
    "    away_win_prob = 0\n",
    "    rest_prob = 0\n",
    "\n",
    "    # 5+ ì ìˆ˜ ì˜ˆì¸¡ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ max_goalì„ 3ìœ¼ë¡œ ì„¤ì •\n",
    "    for h in range(max_goal + 1):\n",
    "        for a in range(max_goal + 1):\n",
    "            p = poisson.pmf(h, mu_home) * poisson.pmf(a, mu_away)\n",
    "            result.append(((h, a), p))\n",
    "            if h > a:\n",
    "                home_win_prob += p\n",
    "            elif h == a:\n",
    "                draw_prob += p\n",
    "            else:\n",
    "                away_win_prob += p\n",
    "\n",
    "    # 5+ ë“ì  ì˜ˆì™¸ ì²˜ë¦¬ í™•ë¥  ê³„ì‚°\n",
    "    for h in range(max_goal + 1):\n",
    "        rest_prob += poisson.pmf(h, mu_home) * (1 - poisson.cdf(max_goal, mu_away))\n",
    "        rest_prob += (1 - poisson.cdf(max_goal, mu_home)) * poisson.pmf(h, mu_away)\n",
    "    rest_prob -= (1 - poisson.cdf(max_goal, mu_home)) * (1 - poisson.cdf(max_goal, mu_away))\n",
    "\n",
    "    # 5+ë¥¼ ì œì™¸í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í™•ë¥ ì„ 0ìœ¼ë¡œ ì„¤ì •\n",
    "    result.append(((\"5+\", \"5+\"), 0))\n",
    "\n",
    "    # ì •ê·œí™”ëœ ìŠ¹/ë¬´/íŒ¨ í™•ë¥ \n",
    "    total = home_win_prob + draw_prob + away_win_prob\n",
    "    home_win_prob /= total\n",
    "    draw_prob /= total\n",
    "    away_win_prob /= total\n",
    "\n",
    "    return {\n",
    "        \"home_expected_goals\": mu_home,\n",
    "        \"away_expected_goals\": mu_away,\n",
    "        \"top_predictions\": sorted(result, key=lambda x: x[1], reverse=True)[:top_k],\n",
    "        \"home_win_prob\": home_win_prob,\n",
    "        \"draw_prob\": draw_prob,\n",
    "        \"away_win_prob\": away_win_prob\n",
    "    }\n",
    "\n",
    "# í‰ê°€ ê²°ê³¼ ì¶œë ¥\n",
    "print(\"âœ… ê²€ì¦ ì„±ëŠ¥:\")\n",
    "y_home_val_pred, _, _, _ = evaluate(model_home, X_val, y_home_val, \"home_val\")\n",
    "y_away_val_pred, _, _, _ = evaluate(model_away, X_val, y_away_val, \"away_val\")\n",
    "\n",
    "print(\"\\nâœ… í…ŒìŠ¤íŠ¸ ì„±ëŠ¥:\")\n",
    "y_home_test_pred, _, _, _ = evaluate(model_home, X_test, y_home_test, \"home_test\")\n",
    "y_away_test_pred, _, _, _ = evaluate(model_away, X_test, y_away_test, \"away_test\")\n",
    "    \n",
    "# Poisson Top-3 ê²°ê³¼ í™•ì¸\n",
    "results = []\n",
    "for i in tqdm(range(len(X_test))):\n",
    "    x = X_test.iloc[[i]]\n",
    "    true_home = y_home_test.iloc[i]\n",
    "    true_away = y_away_test.iloc[i]\n",
    "    pred = predict_scores_with_prob(x, top_k=3)\n",
    "    top_scores = [f\"{h}-{a}\" for (h, a), _ in pred[\"top_predictions\"]]\n",
    "    true_score = f\"{true_home}-{true_away}\"\n",
    "    hit = true_score in top_scores\n",
    "\n",
    "    results.append({\n",
    "        \"True Score\": true_score,\n",
    "        \"Top-1\": top_scores[0],\n",
    "        \"Top-2\": top_scores[1] if len(top_scores) > 1 else \"-\",\n",
    "        \"Top-3\": top_scores[2] if len(top_scores) > 2 else \"-\",\n",
    "        \"Hit in Top-3\": hit\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nğŸ“Š í…ŒìŠ¤íŠ¸ ì „ì²´ì—ì„œ ì‹¤ì œ ìŠ¤ì½”ì–´ê°€ Top-3 ì•ˆì— í¬í•¨ëœ ë¹„ìœ¨:\")\n",
    "print(f\"â†’ {df_results['Hit in Top-3'].mean():.2%}\")\n",
    "\n",
    "# ì‹œê°í™”\n",
    "sns.countplot(data=df_results, x=\"Hit in Top-3\")\n",
    "plt.title(\"Are actual scores included in the Top-3 predictions?\")\n",
    "plt.xlabel(\"Included in Top 3\")\n",
    "plt.ylabel(\"number of cases\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Top-3 ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ:\")\n",
    "print(df_results.head(10))\n",
    "\n",
    "# Feature ì¤‘ìš”ë„ ì‹œê°í™”\n",
    "def plot_feature_importance(model, X_val, y_val, title=\"Permutation Importance\", top_n=20):\n",
    "    result = permutation_importance(model, X_val, y_val, n_repeats=10, random_state=42, scoring='neg_mean_squared_error')\n",
    "    importance_series = pd.Series(result.importances_mean, index=X_val.columns)\n",
    "    top_features = importance_series.sort_values(ascending=False).head(top_n)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_features.sort_values().plot(kind='barh')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Mean Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"\\nğŸ“Š Feature Importance (Home Goal Model)\")\n",
    "plot_feature_importance(model_home, X_val, y_home_val, title=\"Home Goal Feature Importance\", top_n=20)\n",
    "\n",
    "print(\"\\nğŸ“Š Feature Importance (Away Goal Model)\")\n",
    "plot_feature_importance(model_away, X_val, y_away_val, title=\"Away Goal Feature Importance\", top_n=20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b178b0d",
   "metadata": {},
   "source": [
    "ìŠ¹/ë¬´/íŒ¨ ì˜ˆì¸¡ ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d53da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, log_loss, balanced_accuracy_score,\n",
    "    cohen_kappa_score, precision_recall_fscore_support,\n",
    "    classification_report, confusion_matrix, roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from xgboost import XGBClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) ë°ì´í„° ë¡œë”© ë° í†µí•©\n",
    "input_dir = '../../data/datas/2/final'  # ê²½ë¡œ ìˆ˜ì •\n",
    "csv_files = sorted([f for f in os.listdir(input_dir)\n",
    "                    if f.startswith(\"final_\") and f.endswith(\".csv\")])\n",
    "df = pd.concat([pd.read_csv(os.path.join(input_dir, fn))\n",
    "                for fn in csv_files],\n",
    "               ignore_index=True)\n",
    "\n",
    "# 2) ì „ì²˜ë¦¬: ë‚ ì§œ ì •ë ¬ + ìˆ˜ì¹˜í˜• í”¼ì²˜ + íŒ€ ë”ë¯¸\n",
    "df['date'] = pd.to_datetime(df['date_GMT'], errors='coerce')\n",
    "df.sort_values('date', inplace=True)\n",
    "drop_meta = [\n",
    "    'date_GMT','date','season','home_result','away_result',\n",
    "    'home_gk_save_pct','away_gk_save_pct',\n",
    "    'home_team_goal_count','away_team_goal_count'\n",
    "]\n",
    "X_num = (df.drop(columns=drop_meta, errors='ignore')\n",
    "           .select_dtypes(include='number')\n",
    "           .fillna(0))\n",
    "team_dums = pd.get_dummies(\n",
    "    df[['home_team_name','away_team_name']],\n",
    "    prefix=['home','away']\n",
    ")\n",
    "X = pd.concat([X_num, team_dums], axis=1)\n",
    "\n",
    "# 3) ìŠ¹ë¬´íŒ¨(raw) ë ˆì´ë¸” ìƒì„± ë° ì¸ì½”ë”©\n",
    "y_raw = df.apply(\n",
    "    lambda r: 'H' if r['home_team_goal_count'] > r['away_team_goal_count']\n",
    "    else ('D' if r['home_team_goal_count'] == r['away_team_goal_count'] else 'A'),\n",
    "    axis=1\n",
    ")\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_raw)  # Hâ†’0, Dâ†’1, Aâ†’2\n",
    "\n",
    "# 4) í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¶„í•  (60% / 20% / 20%)\n",
    "n = len(X)\n",
    "i1, i2 = int(n*0.6), int(n*0.8)\n",
    "X_tr, X_val, X_te = X.iloc[:i1], X.iloc[i1:i2], X.iloc[i2:]\n",
    "y_tr, y_val, y_te   = y[:i1],     y[i1:i2],   y[i2:]\n",
    "df_te = df.iloc[i2:].reset_index(drop=True)         # í…ŒìŠ¤íŠ¸ êµ¬ê°„ ì›ë³¸\n",
    "\n",
    "# 5) XGBClassifier ì •ì˜ ë° í•™ìŠµ\n",
    "model = XGBClassifier(\n",
    "    n_estimators=500, max_depth=5, learning_rate=0.05,\n",
    "    subsample=0.9, colsample_bytree=0.8, gamma=1,\n",
    "    reg_alpha=1, reg_lambda=1,\n",
    "    use_label_encoder=False, eval_metric='mlogloss',\n",
    "    random_state=42, verbosity=0\n",
    ")\n",
    "model.fit(X_tr, y_tr)\n",
    "\n",
    "# 6) í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡\n",
    "proba = model.predict_proba(X_te)  # (n_samples, 3)\n",
    "pred  = model.predict(X_te)        # 0,1,2\n",
    "\n",
    "# 7) ê²½ê¸°ë³„ ê²°ê³¼ DataFrame ìƒì„±\n",
    "results = pd.DataFrame({\n",
    "    'date_GMT':    df_te['date_GMT'],\n",
    "    'home_team':   df_te['home_team_name'],\n",
    "    'away_team':   df_te['away_team_name'],\n",
    "    'home_goals':  df_te['home_team_goal_count'],\n",
    "    'away_goals':  df_te['away_team_goal_count'],\n",
    "    'actual':      y_raw[i2:].values,\n",
    "    'pred_label':  le.inverse_transform(pred),\n",
    "    'prob_H':      proba[:, le.transform(['H'])[0]],\n",
    "    'prob_D':      proba[:, le.transform(['D'])[0]],\n",
    "    'prob_A':      proba[:, le.transform(['A'])[0]],\n",
    "})\n",
    "\n",
    "# 8) CSVë¡œ ì €ì¥\n",
    "results.to_csv('../../output/matchResult.csv', index=False)\n",
    "print(\"â–¶ 'predictions.csv' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤:\", results.shape)\n",
    "\n",
    "# (ì„ íƒ) 9) Confusion Matrix ì‹œê°í™”\n",
    "cm = confusion_matrix(y_te, pred, labels=[0,1,2])\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "            xticklabels=le.classes_, yticklabels=le.classes_,\n",
    "            cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "118556c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ '../../output/matchResult.csv'ì— ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: (608, 11)\n",
      "â–¶ '../../output/matchResult.csv'ì— ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: (608, 11)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 1) ì „ì²´ ë°ì´í„° ë¡œë”© & ë³‘í•©\n",
    "input_dir = '../../data/datas/2/final'  # ê²½ë¡œ ìˆ˜ì •\n",
    "csv_files = sorted(f for f in os.listdir(input_dir)\n",
    "                   if f.startswith(\"final_\") and f.endswith(\".csv\"))\n",
    "df_list = []\n",
    "for fn in csv_files:\n",
    "    tmp = pd.read_csv(os.path.join(input_dir, fn))\n",
    "    tmp['season'] = fn.replace('final_','').replace('.csv','')\n",
    "    df_list.append(tmp)\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# 2) ì „ì²˜ë¦¬ & í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§\n",
    "df['date_GMT'] = pd.to_datetime(df['date_GMT'], errors='coerce')\n",
    "df.sort_values('date_GMT', inplace=True)\n",
    "drop_meta = [\n",
    "    'date_GMT','date','season',\n",
    "    'home_result','away_result',\n",
    "    'home_gk_save_pct','away_gk_save_pct',\n",
    "    'home_team_goal_count','away_team_goal_count'\n",
    "]\n",
    "X_num = (df\n",
    "         .drop(columns=drop_meta, errors='ignore')\n",
    "         .select_dtypes(include='number')\n",
    "         .fillna(0))\n",
    "team_dums = pd.get_dummies(\n",
    "    df[['home_team_name','away_team_name']],\n",
    "    prefix=['home','away']\n",
    ")\n",
    "X = pd.concat([X_num, team_dums], axis=1)\n",
    "\n",
    "# 3) ë ˆì´ë¸” ìƒì„± & ì¸ì½”ë”© (H/D/A â†’ 0/1/2)\n",
    "y_raw = df.apply(lambda r:\n",
    "    'H' if r.home_team_goal_count > r.away_team_goal_count\n",
    "    else ('D' if r.home_team_goal_count == r.away_team_goal_count else 'A'),\n",
    "    axis=1\n",
    ")\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_raw)\n",
    "\n",
    "# 4) í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¶„í•  (60/20/20)\n",
    "n = len(X)\n",
    "i1, i2 = int(n*0.6), int(n*0.8)\n",
    "X_tr, X_val, X_te = X.iloc[:i1], X.iloc[i1:i2], X.iloc[i2:]\n",
    "y_tr, y_val, y_te   = y[:i1],     y[i1:i2],   y[i2:]\n",
    "df_te = df.iloc[i2:].copy()        # í…ŒìŠ¤íŠ¸ êµ¬ê°„ ì›ë³¸ ë©”íƒ€ì •ë³´\n",
    "\n",
    "# 5) ëª¨ë¸ í•™ìŠµ\n",
    "model = XGBClassifier(\n",
    "    n_estimators=500, max_depth=5, learning_rate=0.05,\n",
    "    subsample=0.9, colsample_bytree=0.8, gamma=1,\n",
    "    reg_alpha=1, reg_lambda=1,\n",
    "    use_label_encoder=False, eval_metric='mlogloss',\n",
    "    random_state=42, verbosity=0\n",
    ")\n",
    "model.fit(X_tr, y_tr)\n",
    "\n",
    "# 6) í…ŒìŠ¤íŠ¸ì…‹ ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼(DataFrame) ìƒì„±\n",
    "proba_te = model.predict_proba(X_te)\n",
    "pred_te  = model.predict(X_te)\n",
    "results_te = df_te[[\n",
    "    'season','date_GMT','home_team_name','away_team_name',\n",
    "    'home_team_goal_count','away_team_goal_count'\n",
    "]].copy()\n",
    "results_te['actual']     = y_raw[i2:].values\n",
    "results_te['pred_label'] = le.inverse_transform(pred_te)\n",
    "results_te['prob_H']     = proba_te[:, le.transform(['H'])[0]]\n",
    "results_te['prob_D']     = proba_te[:, le.transform(['D'])[0]]\n",
    "results_te['prob_A']     = proba_te[:, le.transform(['A'])[0]]\n",
    "\n",
    "# 7) ì „ì²´ dfì—ì„œ â€œì§ì „ 2ê°œ ë¡œìš°â€ ì •ë³´ë¡œ í•„í„°ë§\n",
    "date1 = '2023-12-06 07:30:00 PM'\n",
    "date2 = '2023-12-06 07:30:00 PM'\n",
    "# ë¬¸ìì—´ ë¹„êµë¥¼ ìœ„í•´ í¬ë§· í†µì¼\n",
    "df['date_str'] = df['date_GMT'].dt.strftime('%Y-%m-%d %I:%M:%S %p')\n",
    "\n",
    "mask1 = (\n",
    "    (df['home_team_name']=='Brighton & Hove Albion') &\n",
    "    (df['away_team_name']=='Brentford') &\n",
    "    (df['date_str']==date1)\n",
    ")\n",
    "mask2 = (\n",
    "    (df['home_team_name']=='Fulham') &\n",
    "    (df['away_team_name']=='Nottingham Forest') &\n",
    "    (df['date_str']==date2)\n",
    ")\n",
    "df_up = df[mask1 | mask2].copy()\n",
    "\n",
    "# 8) ì´ ë‘ ê²½ê¸°ë§Œì„ ìœ„í•œ í”¼ì²˜ ì¬ìƒì„±\n",
    "X_up_num  = df_up.drop(columns=drop_meta+['date_str'], errors='ignore') \\\n",
    "                 .select_dtypes(include='number') \\\n",
    "                 .fillna(0)\n",
    "team_dums_up = pd.get_dummies(\n",
    "    df_up[['home_team_name','away_team_name']],\n",
    "    prefix=['home','away']\n",
    ")\n",
    "X_up = pd.concat([X_up_num, team_dums_up], axis=1)\n",
    "X_up = X_up.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# 9) â€œì§ì „ 2ê°œâ€ ì˜ˆì¸¡\n",
    "proba_up = model.predict_proba(X_up)\n",
    "pred_up  = model.predict(X_up)\n",
    "results_up = df_up[[\n",
    "    'season','date_GMT','home_team_name','away_team_name',\n",
    "    'home_team_goal_count','away_team_goal_count'\n",
    "]].copy()\n",
    "results_up['actual']     = df_up.apply(lambda r:\n",
    "    'H' if r.home_team_goal_count > r.away_team_goal_count\n",
    "    else ('D' if r.home_team_goal_count == r.away_team_goal_count else 'A'),\n",
    "    axis=1\n",
    ")\n",
    "results_up['pred_label'] = le.inverse_transform(pred_up)\n",
    "results_up['prob_H']     = proba_up[:, le.transform(['H'])[0]]\n",
    "results_up['prob_D']     = proba_up[:, le.transform(['D'])[0]]\n",
    "results_up['prob_A']     = proba_up[:, le.transform(['A'])[0]]\n",
    "\n",
    "# 10) ë‘ ê²°ê³¼ë¥¼ í•©ì³ CSVë¡œ ì €ì¥\n",
    "final_results = pd.concat([results_te, results_up], ignore_index=True)\n",
    "os.makedirs('../../output', exist_ok=True)\n",
    "final_results.to_csv('../../output/matchResult.csv', index=False)\n",
    "print(\"â–¶ '../../output/matchResult.csv'ì— ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:\", final_results.shape)\n",
    "\n",
    "# 10) ë‘ ê²°ê³¼ë¥¼ í•©ì¹œ ë’¤, ì¶”ê°€ 2ê²½ê¸°(rows_up)ë¥¼ ë§¨ ì•ìœ¼ë¡œ ì´ë™\n",
    "final_results = pd.concat([results_te, results_up], ignore_index=True)\n",
    "\n",
    "# ì¶”ê°€ 2ê²½ê¸° ê°œìˆ˜ë§Œí¼ ì˜ë¼ë‚´ì„œ ë§¨ ì•ìœ¼ë¡œ ë¶™ì´ê¸°\n",
    "n_up = len(results_up)  # ë³´í†µ 2\n",
    "special = final_results.tail(n_up)\n",
    "others  = final_results.iloc[:-n_up]\n",
    "final_results = pd.concat([special, others], ignore_index=True)\n",
    "\n",
    "# 11) CSVë¡œ ì €ì¥\n",
    "os.makedirs('../../output', exist_ok=True)\n",
    "final_results.to_csv('../../output/matchResult.csv', index=False)\n",
    "print(\"â–¶ '../../output/matchResult.csv'ì— ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:\", final_results.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a8471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    roc_curve, auc, precision_recall_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1) ë°ì´í„° ë¡œë”© & í†µí•© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "input_dir = '../../data/datas/2/final'\n",
    "csv_files = sorted(f for f in os.listdir(input_dir)\n",
    "                   if f.startswith(\"final_\") and f.endswith(\".csv\"))\n",
    "df = pd.concat([\n",
    "    pd.read_csv(os.path.join(input_dir, fn)).assign(season=fn.replace('final_','').replace('.csv',''))\n",
    "    for fn in csv_files\n",
    "], ignore_index=True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2) í”¼ì²˜ ì „ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df['date_GMT'] = pd.to_datetime(df['date_GMT'], errors='coerce')\n",
    "df.sort_values('date_GMT', inplace=True)\n",
    "drop_meta = ['date_GMT','date','season','home_result','away_result',\n",
    "             'home_gk_save_pct','away_gk_save_pct',\n",
    "             'home_team_goal_count','away_team_goal_count']\n",
    "X_num  = (df.drop(columns=drop_meta, errors='ignore')\n",
    "            .select_dtypes(include='number')\n",
    "            .fillna(0))\n",
    "dummies = pd.get_dummies(df[['home_team_name','away_team_name']],\n",
    "                         prefix=['home','away'])\n",
    "X = pd.concat([X_num, dummies], axis=1)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3) ë ˆì´ë¸” ìƒì„± & ì¸ì½”ë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "y_raw = df.apply(lambda r:\n",
    "    'H' if r.home_team_goal_count > r.away_team_goal_count else\n",
    "    ('D' if r.home_team_goal_count == r.away_team_goal_count else 'A'),\n",
    "    axis=1\n",
    ")\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_raw)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4) ë¶„í•  (60/20/20) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "n  = len(X)\n",
    "i1, i2 = int(n*0.6), int(n*0.8)\n",
    "X_tr, X_val, X_te = X.iloc[:i1], X.iloc[i1:i2], X.iloc[i2:]\n",
    "y_tr, y_val, y_te = y[:i1], y[i1:i2], y[i2:]\n",
    "df_te = df.iloc[i2:].copy()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5) ëª¨ë¸ í•™ìŠµ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "model = XGBClassifier(\n",
    "    n_estimators=500, max_depth=5, learning_rate=0.05,\n",
    "    subsample=0.9, colsample_bytree=0.8, gamma=1,\n",
    "    reg_alpha=1, reg_lambda=1,\n",
    "    use_label_encoder=False, eval_metric='mlogloss',\n",
    "    random_state=42, verbosity=0\n",
    ")\n",
    "model.fit(X_tr, y_tr)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6) í…ŒìŠ¤íŠ¸ì…‹ ì˜ˆì¸¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "proba_te = model.predict_proba(X_te)\n",
    "pred_te  = model.predict(X_te)\n",
    "results_te = df_te[[\n",
    "    'season','date_GMT','home_team_name','away_team_name',\n",
    "    'home_team_goal_count','away_team_goal_count'\n",
    "]].copy()\n",
    "results_te['actual']      = y_raw[i2:].values\n",
    "results_te['pred_label']  = le.inverse_transform(pred_te)\n",
    "results_te['prob_H']      = proba_te[:, le.transform(['H'])[0]]\n",
    "results_te['prob_D']      = proba_te[:, le.transform(['D'])[0]]\n",
    "results_te['prob_A']      = proba_te[:, le.transform(['A'])[0]]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 7) ì¶”ê°€ 2ê²½ê¸° í•„í„°ë§ & ì˜ˆì¸¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df['date_str'] = df['date_GMT'].dt.strftime('%Y-%m-%d %I:%M:%S %p')\n",
    "mask1 = (df.home_team_name=='Brighton & Hove Albion') & \\\n",
    "        (df.away_team_name=='Brentford') & \\\n",
    "        (df.date_str=='2023-12-06 07:30:00 PM')\n",
    "mask2 = (df.home_team_name=='Fulham') & \\\n",
    "        (df.away_team_name=='Nottingham Forest') & \\\n",
    "        (df.date_str=='2023-12-06 07:30:00 PM')\n",
    "df_up = df[mask1|mask2].copy()\n",
    "\n",
    "X_up = pd.concat([\n",
    "    df_up.drop(columns=drop_meta+['date_str'], errors='ignore')\n",
    "         .select_dtypes(include='number').fillna(0),\n",
    "    pd.get_dummies(df_up[['home_team_name','away_team_name']],\n",
    "                   prefix=['home','away'])\n",
    "], axis=1).reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "proba_up = model.predict_proba(X_up)\n",
    "pred_up  = model.predict(X_up)\n",
    "results_up = df_up[[\n",
    "    'season','date_GMT','home_team_name','away_team_name',\n",
    "    'home_team_goal_count','away_team_goal_count'\n",
    "]].copy()\n",
    "results_up['actual']     = df_up.apply(lambda r:\n",
    "    'H' if r.home_team_goal_count > r.away_team_goal_count else\n",
    "    ('D' if r.home_team_goal_count == r.away_team_goal_count else 'A'),\n",
    "    axis=1)\n",
    "results_up['pred_label']  = le.inverse_transform(pred_up)\n",
    "results_up['prob_H']      = proba_up[:, le.transform(['H'])[0]]\n",
    "results_up['prob_D']      = proba_up[:, le.transform(['D'])[0]]\n",
    "results_up['prob_A']      = proba_up[:, le.transform(['A'])[0]]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 8) ë¶„ë¥˜ ë¦¬í¬íŠ¸ & í˜¼ë™í–‰ë ¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"â–¶ Test Set Classification Report:\")\n",
    "print(classification_report(\n",
    "    results_te['actual'], results_te['pred_label'],\n",
    "    labels=le.classes_, target_names=le.classes_\n",
    "))\n",
    "\n",
    "print(\"\\nâ–¶ Additional 2 Matches Classification Report:\")\n",
    "print(classification_report(\n",
    "    results_up['actual'], results_up['pred_label'],\n",
    "    labels=le.classes_, target_names=le.classes_\n",
    "))\n",
    "\n",
    "# Confusion Matrix (Test)\n",
    "cm = confusion_matrix(results_te['actual'], results_te['pred_label'], labels=le.classes_)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d',\n",
    "            xticklabels=le.classes_, yticklabels=le.classes_, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix (Test Set)\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 9) ROC & PR Curves (Test) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "y_bin = label_binarize(results_te['actual'], classes=le.classes_)\n",
    "plt.figure(figsize=(6,5))\n",
    "for i, cls in enumerate(le.classes_):\n",
    "    fpr, tpr, _ = roc_curve(y_bin[:,i], proba_te[:,i])\n",
    "    plt.plot(fpr, tpr, label=f\"{cls} (AUC={auc(fpr,tpr):.2f})\")\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.title(\"ROC Curves (Test)\"); plt.legend(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "for i, cls in enumerate(le.classes_):\n",
    "    prec, rec, _ = precision_recall_curve(y_bin[:,i], proba_te[:,i])\n",
    "    plt.plot(rec, prec, label=cls)\n",
    "plt.title(\"Precision-Recall Curves (Test)\"); plt.legend(); plt.show()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 10) í™•ë¥  ë¶„í¬ íˆìŠ¤í† ê·¸ë¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(proba_te[:, le.transform(['H'])[0]], bins=20, alpha=0.6, label='P(H)')\n",
    "plt.hist(proba_te[:, le.transform(['D'])[0]], bins=20, alpha=0.6, label='P(D)')\n",
    "plt.hist(proba_te[:, le.transform(['A'])[0]], bins=20, alpha=0.6, label='P(A)')\n",
    "plt.title(\"Predicted Probability Distribution\"); plt.legend(); plt.show()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 11) CSV ì €ì¥ (ì¶”ê°€ 2ê²½ê¸° ë§¨ ì•ìœ¼ë¡œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "final_results = pd.concat([results_up, results_te], ignore_index=True)\n",
    "os.makedirs('../../output', exist_ok=True)\n",
    "final_results.to_csv('../../output/matchResult.csv', index=False)\n",
    "print(f\"â–¶ '../../output/matchResult.csv' ì €ì¥ ì™„ë£Œ: {final_results.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96104fc4",
   "metadata": {},
   "source": [
    "ê²°ê³¼ ë¹„êµ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "518f3323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ ì¼ì¹˜:   376ê±´\n",
      "â–¶ ë¶ˆì¼ì¹˜: 134ê±´\n",
      "\n",
      "â–¶ ë¶ˆì¼ì¹˜ ìƒ˜í”Œ:\n",
      "          date     home_team_name          away_team_name pred_label pred_poi\n",
      "5   2023-12-06  Manchester United                 Chelsea          D        H\n",
      "8   2023-12-09     Crystal Palace               Liverpool          D        A\n",
      "18  2023-12-16    Manchester City          Crystal Palace          D        H\n",
      "21  2023-12-21     Crystal Palace  Brighton & Hove Albion          D        H\n",
      "22  2023-12-22        Aston Villa        Sheffield United          D        A\n",
      "28  2023-12-23          Liverpool                 Arsenal          H        A\n",
      "32  2023-12-26   Sheffield United              Luton Town          H        A\n",
      "47  2024-01-12            Burnley              Luton Town          H        A\n",
      "48  2024-01-13            Chelsea                  Fulham          D        H\n",
      "54  2024-01-21   Sheffield United         West Ham United          A        H\n",
      "\n",
      "â–¶ '../../output/mismatches.csv'ì— ë¶ˆì¼ì¹˜ í•­ëª© ì €ì¥ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user080524\\AppData\\Local\\Temp\\ipykernel_11184\\1676095040.py:25: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  .idxmax(axis=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 1) íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df_cls = pd.read_csv('../../output/1.csv')                  # ë¶„ë¥˜ ëª¨ë¸ ê²°ê³¼\n",
    "df_poi = pd.read_csv('../../output/predicted_score.csv')    # Poisson ì˜ˆì¸¡ ê²°ê³¼\n",
    "\n",
    "# 2) df_poi ì»¬ëŸ¼ëª… í†µì¼\n",
    "df_poi = df_poi.rename(columns={\n",
    "    'Date':                'date_GMT',\n",
    "    'Home Team':           'home_team_name',\n",
    "    'Away Team':           'away_team_name',\n",
    "    'Home Win Probability':'Home Win Probability',\n",
    "    'Draw Probability':    'Draw Probability',\n",
    "    'Away Win Probability':'Away Win Probability'\n",
    "})\n",
    "\n",
    "# 3) ë‚ ì§œ í˜•ì‹ í†µì¼ (ë‚ ì§œ ë¶€ë¶„ë§Œ ë¹„êµ)\n",
    "df_cls['date'] = pd.to_datetime(df_cls['date_GMT']).dt.date\n",
    "df_poi['date'] = pd.to_datetime(df_poi['date_GMT']).dt.date\n",
    "\n",
    "# 4) Poisson ìŠ¹ë¬´íŒ¨(pred_poi) ë ˆì´ë¸” ìƒì„±\n",
    "df_poi['pred_poi'] = (\n",
    "    df_poi[['Home Win Probability','Draw Probability','Away Win Probability']]\n",
    "    .idxmax(axis=1)\n",
    "    .map({\n",
    "        'Home Win Probability':'H',\n",
    "        'Draw Probability':'D',\n",
    "        'Away Win Probability':'A'\n",
    "    })\n",
    ")\n",
    "\n",
    "# 5) í‚¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©\n",
    "keys = ['date','home_team_name','away_team_name']\n",
    "df = pd.merge(\n",
    "    df_cls,\n",
    "    df_poi[keys + ['pred_poi']],\n",
    "    on=keys,\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# 6) ë¶„ë¥˜ ëª¨ë¸(pred_label) vs Poisson(pred_poi) ì¼ì¹˜ ì—¬ë¶€\n",
    "df['match'] = df['pred_label'] == df['pred_poi']\n",
    "\n",
    "# 7) ê²°ê³¼ ì§‘ê³„\n",
    "counts = df['match'].value_counts()\n",
    "print(f\"â–¶ ì¼ì¹˜:   {counts.get(True,0)}ê±´\")\n",
    "print(f\"â–¶ ë¶ˆì¼ì¹˜: {counts.get(False,0)}ê±´\\n\")\n",
    "\n",
    "# 8) ë¶ˆì¼ì¹˜ ìƒ˜í”Œ ë³´ê¸°\n",
    "print(\"â–¶ ë¶ˆì¼ì¹˜ ìƒ˜í”Œ:\")\n",
    "print(df.loc[~df['match'], keys + ['pred_label','pred_poi']].head(10))\n",
    "\n",
    "# 9) ë¶ˆì¼ì¹˜ë§Œ CSVë¡œ ì €ì¥\n",
    "os.makedirs('../../output', exist_ok=True)\n",
    "df.loc[~df['match']].to_csv('../../output/mismatches.csv', index=False)\n",
    "print(\"\\nâ–¶ '../../output/mismatches.csv'ì— ë¶ˆì¼ì¹˜ í•­ëª© ì €ì¥ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd24f3",
   "metadata": {},
   "source": [
    "model pklë¡œ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88966cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ë° feature ì €ì¥ ì™„ë£Œ:\n",
      "ğŸ  Home â†’ ../service\\xgb_model_home.pkl\n",
      "ğŸšŒ Away â†’ ../service\\xgb_model_away.pkl\n",
      "ğŸ“‘ Feature Columns â†’ ../service\\trained_feature_columns.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_save_dir = '../service'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "#ëª¨ë¸ ì €ì¥\n",
    "home_model_path = os.path.join(model_save_dir, 'xgb_model_home.pkl')\n",
    "away_model_path = os.path.join(model_save_dir, 'xgb_model_away.pkl')\n",
    "feature_columns_path = os.path.join(model_save_dir, 'trained_feature_columns.pkl')\n",
    "\n",
    "\n",
    "joblib.dump(model_home, home_model_path)\n",
    "joblib.dump(model_away, away_model_path)\n",
    "joblib.dump(X.columns.to_list(), feature_columns_path)\n",
    "\n",
    "print(f\"âœ… ëª¨ë¸ ë° feature ì €ì¥ ì™„ë£Œ:\\n\"\n",
    "      f\"ğŸ  Home â†’ {home_model_path}\\n\"\n",
    "      f\"ğŸšŒ Away â†’ {away_model_path}\\n\"\n",
    "      f\"ğŸ“‘ Feature Columns â†’ {feature_columns_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e52fd24",
   "metadata": {},
   "source": [
    "prediceted_score ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db97d96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 510/510 [00:14<00:00, 35.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CSV ì €ì¥ ì™„ë£Œ: ../../output/predicted_score.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "test_indices = X_test.index\n",
    "test_df = df.loc[test_indices].reset_index(drop=True)\n",
    "\n",
    "detailed_results = []\n",
    "\n",
    "def clean_score_value(val):\n",
    "    \"\"\"\n",
    "    '05' -> '5', '5+' -> '5+', '00' -> '0', None -> ''\n",
    "    \"\"\"\n",
    "    if val is None:\n",
    "        return \"\"\n",
    "    val_str = str(val).strip()\n",
    "    return val_str.lstrip(\"0\") if val_str != \"0\" and val_str != \"5+\" else val_str\n",
    "\n",
    "for i in tqdm(range(len(X_test))):\n",
    "    x = X_test.iloc[[i]]\n",
    "    pred = predict_scores_with_prob(x, top_k=3)\n",
    "    top_preds = pred[\"top_predictions\"]\n",
    "\n",
    "    row_result = {\n",
    "        \"Date\": test_df.iloc[i][\"date\"].strftime(\"%Y-%m-%d\") if pd.notnull(test_df.iloc[i][\"date\"]) else \"NaT\",\n",
    "        \"Home Team\": test_df.iloc[i][\"home_team_name\"],\n",
    "        \"Away Team\": test_df.iloc[i][\"away_team_name\"],\n",
    "        \"Expected Home Goals\": round(pred[\"home_expected_goals\"], 3),\n",
    "        \"Expected Away Goals\": round(pred[\"away_expected_goals\"], 3),\n",
    "        \"Home Win Probability\": round(pred[\"home_win_prob\"], 4),\n",
    "        \"Draw Probability\": round(pred[\"draw_prob\"], 4),\n",
    "        \"Away Win Probability\": round(pred[\"away_win_prob\"], 4)\n",
    "    }\n",
    "\n",
    "    for rank, ((h, a), prob) in enumerate(top_preds, 1):\n",
    "        h_clean = clean_score_value(h)\n",
    "        a_clean = clean_score_value(a)\n",
    "\n",
    "        score_str = f\"{h_clean}-{a_clean}\" if h_clean != \"\" and a_clean != \"\" else \"\"\n",
    "        row_result[f\"Top-{rank}\"] = f\"'{score_str}'\"  # ë¬¸ìì—´ë¡œ ê°•ì œ ì €ì¥\n",
    "        row_result[f\"Top-{rank} Prob\"] = round(prob, 4) if pd.notnull(prob) else None\n",
    "\n",
    "    detailed_results.append(row_result)\n",
    "\n",
    "df_detailed = pd.DataFrame(detailed_results)\n",
    "output_path = \"../../output/predicted_score.csv\"\n",
    "df_detailed.to_csv(output_path, index=False)\n",
    "print(f\"âœ… CSV ì €ì¥ ì™„ë£Œ: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27d64fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 237/510 [01:25<01:38,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ í™•ë¥  ê²°ì¸¡ â†’ ê±´ë„ˆëœ€: West Ham United vs Chelsea on 2024-09-21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 297/510 [01:46<01:16,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ í™•ë¥  ê²°ì¸¡ â†’ ê±´ë„ˆëœ€: Arsenal vs Nottingham Forest on 2024-11-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 461/510 [02:44<00:17,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ í™•ë¥  ê²°ì¸¡ â†’ ê±´ë„ˆëœ€: Nottingham Forest vs Everton on 2025-04-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 510/510 [03:01<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… model_output í…Œì´ë¸”ì— INSERT ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# 1. DB ì—°ê²°\n",
    "conn = pymysql.connect(\n",
    "    host=\"premo-instance.czwmu86ms4yl.us-east-1.rds.amazonaws.com\",\n",
    "    user=\"admin\",\n",
    "    password=\"tteam891\",\n",
    "    db=\"premo\",\n",
    "    charset=\"utf8mb4\",\n",
    "    cursorclass=pymysql.cursors.DictCursor\n",
    ")\n",
    "\n",
    "# 2. íŒ€ ì´ë¦„ ë§¤í•‘ (CSV â†’ DB)\n",
    "team_folder_map = {\n",
    "    \"AFC Bournemouth\": \"Bournemouth\",\n",
    "    \"Brighton & Hove Albion\" : \"Brighton\"\n",
    "}\n",
    "\n",
    "# 3. team_name â†’ team_id ë§¤í•‘ (common_name + short_name, ì†Œë¬¸ì)\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(\"SELECT team_id, team_common_name, short_name FROM team\")\n",
    "    team_rows = cursor.fetchall()\n",
    "\n",
    "team_name_to_id = {}\n",
    "for row in team_rows:\n",
    "    team_name_to_id[row['team_common_name'].lower()] = row['team_id']\n",
    "    team_name_to_id[row['short_name'].lower()] = row['team_id']\n",
    "\n",
    "# 4. CSV ë¡œë”©\n",
    "df = pd.read_csv(\"../../output/predicted_score.csv\")\n",
    "\n",
    "# 5. INSERT SQL\n",
    "insert_sql = \"\"\"\n",
    "INSERT INTO model_output (\n",
    "    match_id,\n",
    "    home_winrate, drawrate, away_winrate,\n",
    "    home_score_1, away_score_1, score_1_prob,\n",
    "    home_score_2, away_score_2, score_2_prob,\n",
    "    home_score_3, away_score_3, score_3_prob,\n",
    "    prediction_date, created_at, updated_at\n",
    ") VALUES (\n",
    "    %(match_id)s,\n",
    "    %(home_winrate)s, %(drawrate)s, %(away_winrate)s,\n",
    "    %(home_score_1)s, %(away_score_1)s, %(score_1_prob)s,\n",
    "    %(home_score_2)s, %(away_score_2)s, %(score_2_prob)s,\n",
    "    %(home_score_3)s, %(away_score_3)s, %(score_3_prob)s,\n",
    "    NOW(), NOW(), NOW()\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# 6. INSERT ë°˜ë³µ\n",
    "with conn.cursor() as cursor:\n",
    "    for i in tqdm(range(len(df))):\n",
    "        row = df.iloc[i]\n",
    "\n",
    "        # ê²°ì¸¡ê°’ ì¡´ì¬ ì‹œ ìŠ¤í‚µ\n",
    "        if pd.isna(row[\"Home Win Probability\"]) or pd.isna(row[\"Draw Probability\"]) or pd.isna(row[\"Away Win Probability\"]):\n",
    "            print(f\"âš ï¸ í™•ë¥  ê²°ì¸¡ â†’ ê±´ë„ˆëœ€: {row.get('Home Team')} vs {row.get('Away Team')} on {row.get('Date')}\")\n",
    "            continue\n",
    "\n",
    "        # íŒ€ ì´ë¦„ ë§¤í•‘ ì ìš©\n",
    "        home_team_name = team_folder_map.get(row[\"Home Team\"], row[\"Home Team\"]).lower()\n",
    "        away_team_name = team_folder_map.get(row[\"Away Team\"], row[\"Away Team\"]).lower()\n",
    "\n",
    "        home_team_id = team_name_to_id.get(home_team_name)\n",
    "        away_team_id = team_name_to_id.get(away_team_name)\n",
    "        row_date = pd.to_datetime(row[\"Date\"]).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        if home_team_id is None or away_team_id is None:\n",
    "            print(f\"âŒ íŒ€ ID ë§¤í•‘ ì‹¤íŒ¨: {row['Home Team']} / {row['Away Team']}\")\n",
    "            continue\n",
    "\n",
    "        # match_id ì°¾ê¸°\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT match_id FROM `match`\n",
    "            WHERE home_team_id = %s AND away_team_id = %s AND start_time = %s\n",
    "        \"\"\", (home_team_id, away_team_id, row_date))\n",
    "        result = cursor.fetchone()\n",
    "\n",
    "        if not result:\n",
    "            print(f\"âŒ Match not found: {row['Home Team']} vs {row['Away Team']} on {row['Date']}\")\n",
    "            continue\n",
    "\n",
    "        match_id = result[\"match_id\"]\n",
    "\n",
    "        # INSERT ë°ì´í„° êµ¬ì„±\n",
    "        insert_data = {\n",
    "            \"match_id\": match_id,\n",
    "            \"home_winrate\": round(float(row[\"Home Win Probability\"]) * 100, 2),\n",
    "            \"drawrate\": round(float(row[\"Draw Probability\"]) * 100, 2),\n",
    "            \"away_winrate\": round(float(row[\"Away Win Probability\"]) * 100, 2),\n",
    "        }\n",
    "\n",
    "        for k in range(1, 4):\n",
    "            score = str(row.get(f\"Top-{k}\", \"\")).replace(\"'\", \"\").strip()\n",
    "            prob = row.get(f\"Top-{k} Prob\", 0)\n",
    "\n",
    "            if \"-\" in score:\n",
    "                h, a = score.split(\"-\", 1)\n",
    "                h = h.strip()\n",
    "                a = a.strip()\n",
    "            else:\n",
    "                h, a = None, None\n",
    "\n",
    "            insert_data[f\"home_score_{k}\"] = h if h else None\n",
    "            insert_data[f\"away_score_{k}\"] = a if a else None\n",
    "            insert_data[f\"score_{k}_prob\"] = float(prob) * 100 if pd.notnull(prob) else None\n",
    "            \n",
    "        cursor.execute(insert_sql, insert_data)\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "print(\"âœ… model_output í…Œì´ë¸”ì— INSERT ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c03cd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 608/608 [03:36<00:00,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… model_output.predictedResult ì—…ë°ì´íŠ¸ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# 1. DB ì—°ê²°\n",
    "conn = pymysql.connect(\n",
    "    host=\"premo-instance.czwmu86ms4yl.us-east-1.rds.amazonaws.com\",\n",
    "    user=\"admin\",\n",
    "    password=\"tteam891\",\n",
    "    db=\"premo\",\n",
    "    charset=\"utf8mb4\",\n",
    "    cursorclass=pymysql.cursors.DictCursor\n",
    ")\n",
    "\n",
    "# 2. íŒ€ ì´ë¦„ ë§¤í•‘ (CSV â†’ DB)\n",
    "team_folder_map = {\n",
    "    \"AFC Bournemouth\": \"Bournemouth\",\n",
    "    \"Brighton & Hove Albion\" : \"Brighton\"\n",
    "}\n",
    "\n",
    "# 3. team_name â†’ team_id ë§¤í•‘ (common_name + short_name, ì†Œë¬¸ì)\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(\"SELECT team_id, team_common_name, short_name FROM team\")\n",
    "    team_rows = cursor.fetchall()\n",
    "\n",
    "team_name_to_id = {}\n",
    "for row in team_rows:\n",
    "    team_name_to_id[row['team_common_name'].lower()] = row['team_id']\n",
    "    team_name_to_id[row['short_name'].lower()] = row['team_id']\n",
    "\n",
    "# 4. CSV ë¡œë”©\n",
    "df = pd.read_csv(\"../../output/matchResult.csv\")\n",
    "\n",
    "# 5) UPDATE ë¬¸ ì¤€ë¹„\n",
    "update_sql = \"\"\"\n",
    "UPDATE model_output\n",
    "SET predictedResult = %s,\n",
    "    updated_at = NOW()\n",
    "WHERE match_id = %s\n",
    "\"\"\"\n",
    "\n",
    "# 6) í•œ ê±´ì”© ë£¨í”„ ëŒë©° match_id ì°¾ê³  UPDATE\n",
    "with conn.cursor() as cur:\n",
    "    for _, r in tqdm(df.iterrows(), total=len(df)):\n",
    "        # 6.1) íŒ€ëª… í‘œì¤€í™” â†’ ì†Œë¬¸ì\n",
    "        home = team_folder_map.get(r['home_team_name'], r['home_team_name']).lower()\n",
    "        away = team_folder_map.get(r['away_team_name'], r['away_team_name']).lower()\n",
    "\n",
    "        # 6.2) team_id ì¡°íšŒ\n",
    "        hid = team_name_to_id.get(home)\n",
    "        aid = team_name_to_id.get(away)\n",
    "        if hid is None or aid is None:\n",
    "            print(f\"âš ï¸ íŒ€ID ì—†ìŒ: {r['home_team_name']}, {r['away_team_name']}\")\n",
    "            continue\n",
    "\n",
    "        # 6.3) ë‚ ì§œ í¬ë§· ë§ì¶”ê¸° (YYYY-MM-DD)\n",
    "        match_date = pd.to_datetime(r['date_GMT']).strftime('%Y-%m-%d')\n",
    "\n",
    "        # 6.4) match_id ì¡°íšŒ\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT match_id\n",
    "              FROM `match`\n",
    "             WHERE home_team_id=%s\n",
    "               AND away_team_id=%s\n",
    "               AND DATE(start_time)= %s\n",
    "        \"\"\", (hid, aid, match_date))\n",
    "        m = cur.fetchone()\n",
    "        if not m:\n",
    "            print(f\"âš ï¸ Match ë¯¸ë°œê²¬: {r['home_team_name']} vs {r['away_team_name']} on {match_date}\")\n",
    "            continue\n",
    "\n",
    "        match_id = m['match_id']\n",
    "        pred     = r['pred_label']  # H, D, A\n",
    "\n",
    "        # 6.5) model_output.predictedResult ì—…ë°ì´íŠ¸\n",
    "        cur.execute(update_sql, (pred, match_id))\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "conn.close()\n",
    "print(\"âœ… model_output.predictedResult ì—…ë°ì´íŠ¸ ì™„ë£Œ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
